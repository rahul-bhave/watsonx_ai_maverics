{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  Use watsonx, and `ibm/granite-13b-instruct-v2` \n",
    "To analyze customer satisfaction based on the feedback provided by customers who are using electronic devices manufactured by a specific company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install and import the `datasets` and dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from scikit-learn==1.3.2) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/conda/envs/Python-RT23.1/lib/python3.10/site-packages (from anyio->httpx->ibm-watsonx-ai) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets | tail -n 1\n",
    "!pip install \"scikit-learn==1.3.2\" | tail -n 1\n",
    "!pip install -U ibm-watsonx-ai | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the WML credentials\n",
    "This cell defines the WML credentials required to work with watsonx Foundation Model inferencing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your WML api key (hit enter): ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "from ibm_watsonx_ai import Credentials\n",
    "\n",
    "credentials = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key=getpass.getpass(\"Please enter your WML api key (hit enter): \"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the project id\n",
    "The Foundation Model requires project id that provides the context for the call. We will obtain the id from the project in which this notebook runs. Otherwise, please provide the project id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "except KeyError:\n",
    "    project_id = input(\"Please enter your project_id (hit enter): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Customer_Service  Satisfaction\n",
      "0                                  The device is good.             1\n",
      "1    Absolutely love this VR headset! It’s a game-c...             1\n",
      "2        The device works perfectly, no issues so far!             1\n",
      "3    The screen resolution on this laptop is amazin...             0\n",
      "4    Picture quality is stunning! Gaming feels supe...             1\n",
      "..                                                 ...           ...\n",
      "495  Fantastic device, really happy with this purch...             1\n",
      "496  Great product for the price! I use it daily an...             1\n",
      "497  Fantastic sound quality, perfect for long list...             1\n",
      "498  Fantastic sound quality, perfect for long list...             1\n",
      "499  Disappointed with the camera performance in lo...             0\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the raw CSV file from GitHub (replace with your actual URL)\n",
    "url = \"https://raw.githubusercontent.com/rahul-bhave/watsonx_ai_maverics/main/electronic_device_customer_feedback.csv\"\n",
    "\n",
    "# Load the CSV file directly from the GitHub URL\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Extract only the required columns\n",
    "data = df[['Customer_Service', 'Satisfaction']]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Examine downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Service</th>\n",
       "      <th>Satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The device is good.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Absolutely love this VR headset! It’s a game-c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The device works perfectly, no issues so far!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The screen resolution on this laptop is amazin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Picture quality is stunning! Gaming feels supe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Customer_Service  Satisfaction\n",
       "0                                The device is good.             1\n",
       "1  Absolutely love this VR headset! It’s a game-c...             1\n",
       "2      The device works perfectly, no issues so far!             1\n",
       "3  The screen resolution on this laptop is amazin...             0\n",
       "4  Picture quality is stunning! Gaming feels supe...             1"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prepare train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.5)\n",
    "comments = list(test.Customer_Service)\n",
    "satisfaction = list(test.Satisfaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"models\"></a>\n",
    "## Foundation Models on `watsonx.ai`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### List available models\n",
    "\n",
    "We will list out all avilable models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FLAN_T5_XXL', 'FLAN_UL2', 'MT0_XXL', 'GPT_NEOX', 'MPT_7B_INSTRUCT2', 'STARCODER', 'LLAMA_2_70B_CHAT', 'LLAMA_2_13B_CHAT', 'GRANITE_13B_INSTRUCT', 'GRANITE_13B_CHAT', 'FLAN_T5_XL', 'GRANITE_13B_CHAT_V2', 'GRANITE_13B_INSTRUCT_V2', 'ELYZA_JAPANESE_LLAMA_2_7B_INSTRUCT', 'MIXTRAL_8X7B_INSTRUCT_V01_Q', 'CODELLAMA_34B_INSTRUCT_HF', 'GRANITE_20B_MULTILINGUAL', 'MERLINITE_7B', 'GRANITE_20B_CODE_INSTRUCT', 'GRANITE_34B_CODE_INSTRUCT', 'GRANITE_3B_CODE_INSTRUCT', 'GRANITE_7B_LAB', 'GRANITE_8B_CODE_INSTRUCT', 'LLAMA_3_70B_INSTRUCT', 'LLAMA_3_8B_INSTRUCT', 'MIXTRAL_8X7B_INSTRUCT_V01']\n"
     ]
    }
   ],
   "source": [
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes\n",
    "\n",
    "print([model.name for model in ModelTypes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Get the model id\n",
    "Get the `model_id` that will be used in next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_id = ModelTypes.GRANITE_13B_INSTRUCT_V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Defining the model parameters\n",
    "\n",
    "Define model parameters such as min, max new tokens, decoding method selected Greedy as well as repetition penalty is mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "parameters = {\n",
    "    GenParams.MIN_NEW_TOKENS: 0,\n",
    "    GenParams.MAX_NEW_TOKENS: 1,\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.REPETITION_PENALTY: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialize the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "\n",
    "model = ModelInference(\n",
    "    model_id=model_id, \n",
    "    params=parameters, \n",
    "    credentials=credentials,\n",
    "    project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model's details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_id': 'ibm/granite-13b-instruct-v2',\n",
       " 'label': 'granite-13b-instruct-v2',\n",
       " 'provider': 'IBM',\n",
       " 'source': 'IBM',\n",
       " 'functions': [{'id': 'prompt_tune_inferable'},\n",
       "  {'id': 'prompt_tune_trainable'},\n",
       "  {'id': 'text_generation'}],\n",
       " 'short_description': 'The Granite model series is a family of IBM-trained, dense decoder-only models, which are particularly well-suited for generative tasks.',\n",
       " 'long_description': 'Granite models are designed to be used for a wide range of generative and non-generative tasks with appropriate prompt engineering. They employ a GPT-style decoder-only architecture, with additional innovations from IBM Research and the open community.',\n",
       " 'input_tier': 'class_1',\n",
       " 'output_tier': 'class_1',\n",
       " 'number_params': '13b',\n",
       " 'min_shot_size': 0,\n",
       " 'task_ids': ['question_answering',\n",
       "  'summarization',\n",
       "  'classification',\n",
       "  'generation',\n",
       "  'extraction'],\n",
       " 'tasks': [{'id': 'question_answering', 'ratings': {'quality': 3}},\n",
       "  {'id': 'summarization',\n",
       "   'ratings': {'quality': 2},\n",
       "   'tags': ['function_prompt_tune_trainable'],\n",
       "   'training_parameters': {'init_method': {'supported': ['random', 'text'],\n",
       "     'default': 'text'},\n",
       "    'init_text': {'default': 'Please write a summary highlighting the main points of the following text:'},\n",
       "    'num_virtual_tokens': {'supported': [20, 50, 100], 'default': 100},\n",
       "    'num_epochs': {'default': 40, 'min': 1, 'max': 50},\n",
       "    'verbalizer': {'default': 'Please write a summary highlighting the main points of the following text: {{input}}'},\n",
       "    'batch_size': {'default': 8, 'min': 1, 'max': 16},\n",
       "    'max_input_tokens': {'default': 256, 'min': 1, 'max': 1024},\n",
       "    'max_output_tokens': {'default': 128, 'min': 1, 'max': 512},\n",
       "    'torch_dtype': {'default': 'bfloat16'},\n",
       "    'accumulate_steps': {'default': 1, 'min': 1, 'max': 128},\n",
       "    'learning_rate': {'default': 0.0002, 'min': 1e-05, 'max': 0.5}}},\n",
       "  {'id': 'retrieval_augmented_generation', 'ratings': {'quality': 2}},\n",
       "  {'id': 'classification',\n",
       "   'ratings': {'quality': 3},\n",
       "   'tags': ['function_prompt_tune_trainable'],\n",
       "   'training_parameters': {'init_method': {'supported': ['random', 'text'],\n",
       "     'default': 'text'},\n",
       "    'init_text': {'default': 'Classify the text:'},\n",
       "    'num_virtual_tokens': {'supported': [20, 50, 100], 'default': 100},\n",
       "    'num_epochs': {'default': 20, 'min': 1, 'max': 50},\n",
       "    'verbalizer': {'default': 'Input: {{input}} Output:'},\n",
       "    'batch_size': {'default': 8, 'min': 1, 'max': 16},\n",
       "    'max_input_tokens': {'default': 256, 'min': 1, 'max': 1024},\n",
       "    'max_output_tokens': {'default': 128, 'min': 1, 'max': 512},\n",
       "    'torch_dtype': {'default': 'bfloat16'},\n",
       "    'accumulate_steps': {'default': 32, 'min': 1, 'max': 128},\n",
       "    'learning_rate': {'default': 0.0006, 'min': 1e-05, 'max': 0.5}}},\n",
       "  {'id': 'generation',\n",
       "   'tags': ['function_prompt_tune_trainable'],\n",
       "   'training_parameters': {'init_method': {'supported': ['random', 'text'],\n",
       "     'default': 'text'},\n",
       "    'init_text': {'default': 'text'},\n",
       "    'num_virtual_tokens': {'supported': [20, 50, 100], 'default': 100},\n",
       "    'num_epochs': {'default': 20, 'min': 1, 'max': 50},\n",
       "    'verbalizer': {'default': '{{input}}'},\n",
       "    'batch_size': {'default': 16, 'min': 1, 'max': 16},\n",
       "    'max_input_tokens': {'default': 256, 'min': 1, 'max': 1024},\n",
       "    'max_output_tokens': {'default': 128, 'min': 1, 'max': 512},\n",
       "    'torch_dtype': {'default': 'bfloat16'},\n",
       "    'accumulate_steps': {'default': 16, 'min': 1, 'max': 128},\n",
       "    'learning_rate': {'default': 0.0002, 'min': 1e-05, 'max': 0.5}}},\n",
       "  {'id': 'extraction', 'ratings': {'quality': 2}}],\n",
       " 'model_limits': {'max_sequence_length': 8192,\n",
       "  'max_output_tokens': 8191,\n",
       "  'training_data_max_records': 10000},\n",
       " 'limits': {'lite': {'call_time': '5m0s', 'max_output_tokens': 8191},\n",
       "  'v2-professional': {'call_time': '10m0s', 'max_output_tokens': 8191},\n",
       "  'v2-standard': {'call_time': '10m0s', 'max_output_tokens': 8191}},\n",
       " 'lifecycle': [{'id': 'available', 'start_date': '2023-12-01'}],\n",
       " 'training_parameters': {'init_method': {'supported': ['random', 'text'],\n",
       "   'default': 'random'},\n",
       "  'init_text': {'default': 'text'},\n",
       "  'num_virtual_tokens': {'supported': [20, 50, 100], 'default': 100},\n",
       "  'num_epochs': {'default': 20, 'min': 1, 'max': 50},\n",
       "  'verbalizer': {'default': '{{input}}'},\n",
       "  'batch_size': {'default': 16, 'min': 1, 'max': 16},\n",
       "  'max_input_tokens': {'default': 256, 'min': 1, 'max': 1024},\n",
       "  'max_output_tokens': {'default': 128, 'min': 1, 'max': 512},\n",
       "  'torch_dtype': {'default': 'bfloat16'},\n",
       "  'accumulate_steps': {'default': 16, 'min': 1, 'max': 128},\n",
       "  'learning_rate': {'default': 0.0002, 'min': 1e-05, 'max': 0.5}}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"predict\"></a>\n",
    "## Analyze the satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Prepare prompt and generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"Determine if the customer was satisfied with the experience based on the comment. Return simple yes or no.\n",
    "Comment:Returned the product as it didn’t match the description on the website.\n",
    "Satisfied:no\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determine if the customer was satisfied with the experience based on the comment. Return simple yes or no.\n",
      "Comment:Returned the product as it didn’t match the description on the website.\n",
      "Satisfied:no\n",
      "Comment:Returned the product as it didn’t match the description on the website.\n",
      "Satisfied:\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"\\n\".join([instruction, \"Comment:\" + comments[2], \"Satisfied:\"])\n",
    "print(prompt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Analyze the sentiment for a sample of zero-shot input from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "print(model.generate_text(prompt=prompt1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_size = 10\n",
    "prompts_batch = [\"\\n\".join([instruction, \"Comment:\" + comment, \"Satisfied:\"]) for comment in comments[:10]]\n",
    "results = model.generate_text(prompt=prompts_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determine if the customer was satisfied with the experience based on the comment. Return simple yes or no.\n",
      "Comment:Returned the product as it didn’t match the description on the website.\n",
      "Satisfied:no\n",
      "Comment:Sound is not proper when you play jazz.\n",
      "Satisfied:\n"
     ]
    }
   ],
   "source": [
    "print(prompts_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"score\"></a>\n",
    "## Score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "label_map = {0: \"no\", 1: \"yes\"}\n",
    "y_true = [label_map[sat] for sat in satisfaction][:sample_size]\n",
    "\n",
    "print('accuracy_score', accuracy_score(y_true, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true ['no', 'no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes'] \n",
      "pred ['no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']\n"
     ]
    }
   ],
   "source": [
    "print('true', y_true, '\\npred', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### References:\n",
    "1. https://dataplatform.cloud.ibm.com/exchange/public/entry/view/61c1e967-8d10-44bb-a846-cc1f27e9e69a?context=wx\n",
    "2. https://github.com/IBM/watson-machine-learning-samples/blob/master/README.md\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
